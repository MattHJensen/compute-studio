{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"COMP Docs Welcome to COMP CE's development documentation! Publish Check out our guide for publishing on compmodels.org .","title":"Home"},{"location":"#comp-docs","text":"Welcome to COMP CE's development documentation!","title":"COMP Docs"},{"location":"#publish","text":"Check out our guide for publishing on compmodels.org .","title":"Publish"},{"location":"publish/endpoints/","text":"Python functions The modeling project must provide a Python function for each of the following tasks: - Model Parameters : Get the default Model Parameters and their meta data. - Parse user adjustments : Do model-specific formatting and validation on user adjustments. - Run simulation : Submit the user adjustments (or none) to the model to run the simulation. Model Parameters Accepts Meta Parameters, if they are being utilized. Returns data in the form specified in the inputs page . Python Example : import matchups def package_defaults(**meta_parameters): metaparams = matchups.MetaParams(array_first=True) metaparams.adjust(meta_parameters) params = matchups.MatchupsParams() params.set_state(use_full_data=metaparams.use_full_data) return params.specification(meta_data=True) Here's what you get after filling in this function: Validate user adjustments Accepts parsed user adjustments, separated by each major section. Returns warnings/errors (if any). COMP will provide parsed user adjustments of the form: { \"matchup\": { \"start_date\": [{\"value\": \"2012-08-01\"}], \"end_date\": [{\"value\": \"2012-09-01\"}], \"pitcher\": [{\"value\": \"Not a Real Pitcher\"}], } } The function should return: Warnings/Errors: { \"matchup\": { \"errors\": { \"pitcher\": [\"Pitcher \\\"Not a Real Pitcher\\\" not allowed\"] }, \"warnings\": {} } } Python : import matchups def validate_user_inputs(params, errors_warnings, **meta_parameters): # validate the parameters. adjustments = params[\"matchup\"] params = MatchupsParams() params.adjust(adjustments, raise_errors=False) errors_warnings[\"matchup\"][\"errors\"].update(params.errors) return errors_warnings Here's what you get after filling in this function: Run simulation Accepts Meta Parameters values and model parameters. Returns outputs as specified in the outputs page COMP submits the model's meta parameters and the parsed and formatted user adjustments: { \"meta_parameter1\": value, \"meta_parameter2\": value, ... \"user_mods\": { \"major_section1\": { ... }, \"major_section2\": { ... }, ... } } Python Example : import matchups def run(**run_args): meta_data = run_args[\"meta_params\"] model_parameters = run_args[\"model_parameters\"] result = matchups.get_matchup(meta_data, model_parameters) return result Here's what you get after filling in this function:","title":"Endpoints"},{"location":"publish/endpoints/#python-functions","text":"The modeling project must provide a Python function for each of the following tasks: - Model Parameters : Get the default Model Parameters and their meta data. - Parse user adjustments : Do model-specific formatting and validation on user adjustments. - Run simulation : Submit the user adjustments (or none) to the model to run the simulation.","title":"Python functions"},{"location":"publish/endpoints/#model-parameters","text":"Accepts Meta Parameters, if they are being utilized. Returns data in the form specified in the inputs page . Python Example : import matchups def package_defaults(**meta_parameters): metaparams = matchups.MetaParams(array_first=True) metaparams.adjust(meta_parameters) params = matchups.MatchupsParams() params.set_state(use_full_data=metaparams.use_full_data) return params.specification(meta_data=True) Here's what you get after filling in this function:","title":"Model Parameters"},{"location":"publish/endpoints/#validate-user-adjustments","text":"Accepts parsed user adjustments, separated by each major section. Returns warnings/errors (if any). COMP will provide parsed user adjustments of the form: { \"matchup\": { \"start_date\": [{\"value\": \"2012-08-01\"}], \"end_date\": [{\"value\": \"2012-09-01\"}], \"pitcher\": [{\"value\": \"Not a Real Pitcher\"}], } } The function should return: Warnings/Errors: { \"matchup\": { \"errors\": { \"pitcher\": [\"Pitcher \\\"Not a Real Pitcher\\\" not allowed\"] }, \"warnings\": {} } } Python : import matchups def validate_user_inputs(params, errors_warnings, **meta_parameters): # validate the parameters. adjustments = params[\"matchup\"] params = MatchupsParams() params.adjust(adjustments, raise_errors=False) errors_warnings[\"matchup\"][\"errors\"].update(params.errors) return errors_warnings Here's what you get after filling in this function:","title":"Validate user adjustments"},{"location":"publish/endpoints/#run-simulation","text":"Accepts Meta Parameters values and model parameters. Returns outputs as specified in the outputs page COMP submits the model's meta parameters and the parsed and formatted user adjustments: { \"meta_parameter1\": value, \"meta_parameter2\": value, ... \"user_mods\": { \"major_section1\": { ... }, \"major_section2\": { ... }, ... } } Python Example : import matchups def run(**run_args): meta_data = run_args[\"meta_params\"] model_parameters = run_args[\"model_parameters\"] result = matchups.get_matchup(meta_data, model_parameters) return result Here's what you get after filling in this function:","title":"Run simulation"},{"location":"publish/environment/","text":"Model Environment COMP runs each project in its own Docker container. Miniconda3 is used as the base image. This means that conda is installed by default. Thus, all packages available through the conda package manager can easily be installed. Include installation instructions in your email to Hank, and he will add them to the project's Dockerfile . If you are inclined, you will have access to this Dockerfile and will be able to build the Docker image and experiment with it. The installation instructions for the matchups project are simply a bash script: conda install pandas pyarrow pip install pybaseball matchups","title":"Environment"},{"location":"publish/environment/#model-environment","text":"COMP runs each project in its own Docker container. Miniconda3 is used as the base image. This means that conda is installed by default. Thus, all packages available through the conda package manager can easily be installed. Include installation instructions in your email to Hank, and he will add them to the project's Dockerfile . If you are inclined, you will have access to this Dockerfile and will be able to build the Docker image and experiment with it. The installation instructions for the matchups project are simply a bash script: conda install pandas pyarrow pip install pybaseball matchups","title":"Model Environment"},{"location":"publish/guide/","text":"Publishing on COMP This guide describes how to publish a model on COMP. The COMP framework depends on model interfaces meeting several COMP criteria, and we walk you through how to meet those criteria, either by modifying your model's interface or building a new wrapper interface around your model. The great part is that you don't have to deal with any web technology to build your COMP app. If you have any questions as you proceed through this guide, send Hank an email at henrymdoupe@gmail.com. The documentation is split into three parts. The first part documents the inputs and outputs JSON schemas that your model will need to adopt for COMP to be able to generate input forms representing your model's default specification, validate user adjustments, and display model outputs. The second part documents the python functions that will be used by COMP to get data from and submit data to your model. The third part is a publish form that asks you to provide a title and overview for your new COMP app, code snippets for the three python functions, and information describing your app's resource requirements and installation directions. If you would like to see a publishing template that has already been completed, you can view the Matchups template here . Once you've submitted the publishing form, Hank will review it and get back to you within 24 hours to inform you whether the model is ready to be published or if there are criteria that have not been satisfied. Your model will be deployed to COMP once it has met all of the critera. You will have the opportunity to test it out after it has been deployed. For those who are interested in a more detailed explanation of the additional steps we take to publish your model on COMP, feel free to checkout the Technical Publishing Guide , and, since COMP is an open-source website, you can even follow along.","title":"Guide"},{"location":"publish/guide/#publishing-on-comp","text":"This guide describes how to publish a model on COMP. The COMP framework depends on model interfaces meeting several COMP criteria, and we walk you through how to meet those criteria, either by modifying your model's interface or building a new wrapper interface around your model. The great part is that you don't have to deal with any web technology to build your COMP app. If you have any questions as you proceed through this guide, send Hank an email at henrymdoupe@gmail.com. The documentation is split into three parts. The first part documents the inputs and outputs JSON schemas that your model will need to adopt for COMP to be able to generate input forms representing your model's default specification, validate user adjustments, and display model outputs. The second part documents the python functions that will be used by COMP to get data from and submit data to your model. The third part is a publish form that asks you to provide a title and overview for your new COMP app, code snippets for the three python functions, and information describing your app's resource requirements and installation directions. If you would like to see a publishing template that has already been completed, you can view the Matchups template here . Once you've submitted the publishing form, Hank will review it and get back to you within 24 hours to inform you whether the model is ready to be published or if there are criteria that have not been satisfied. Your model will be deployed to COMP once it has met all of the critera. You will have the opportunity to test it out after it has been deployed. For those who are interested in a more detailed explanation of the additional steps we take to publish your model on COMP, feel free to checkout the Technical Publishing Guide , and, since COMP is an open-source website, you can even follow along.","title":"Publishing on COMP"},{"location":"publish/inputs/","text":"Inputs COMP uses the ParamTools inputs format for building its GUI. ParamTools also offers functionality for updating parameter values and validating the new values. Check out the ParamTools documentation for more information on how to create your configuration files. COMP requires two typs of inputs: meta parameters and model parameters. First, what are meta parameters ? Meta parameters control the default parameters. If the value of a parameter depends on the current year, then the user will need to set the current year via a meta parameter before they can view the parameter's default value and update it. Meta Parameters For example, the meta parameters for PSLmodels/Tax-Brain are defined like this: { \"schema\": { \"labels\": {}, \"additional_members\": {} }, \"start_year\": { \"title\": \"Start Year\", \"description\": \"Year for parameters.\", \"type\": \"int\", \"value\": 2019, \"validators\": {\"range\": {\"min\": 2019, \"max\": 2027}} }, \"data_source\": { \"title\": \"Data Source\", \"description\": \"Data source can be PUF or CPS\", \"type\": \"str\", \"value\": \"PUF\", \"validators\": {\"choice\": {\"choices\": [\"PUF\", \"CPS\"]}} }, \"use_full_sample\": { \"title\": \"Use Full Sample\", \"description\": \"Use entire data set or a 2% sample.\", \"type\": \"str\", \"value\": true, \"validators\": {} } } COMP uses this information to build a set of controls that dictate which values of the default model parameters are shown: Default Parameters The GUI is built directly from the default parameters. Here's an example using a subset of the inputs from the hdoupe/Matchups app: { \"schema\": { \"labels\": { \"use_full_data\": {\"type\": \"bool\", \"validators\": {}} }, \"additional_parameters\": { \"section_1\": {\"type\": \"str\", \"number_dims\": 0}, \"section_2\": {\"type\": \"str\", \"number_dims\": 0} } }, \"start_date\": { \"title\": \"Start Date\", \"description\": \"Date to start pulling statcast information\", \"section_1\": \"Date\", \"section_2\": \"\", \"notes\": \"If using the 2018 dataset, only use dates in 2018.\", \"type\": \"date\", \"value\": [ {\"use_full_data\": true, \"value\": \"2008-01-01\"}, {\"use_full_data\": false, \"value\": \"2018-01-01\"} ], \"validators\": {\"date_range\": {\"min\": \"2008-01-01\", \"max\": \"end_date\"}} }, \"pitcher\": { \"title\": \"Pitcher Name\", \"description\": \"Name of pitcher to pull data on\", \"section_1\": \"Parameters\", \"section_2\": \"Pitcher\", \"type\": \"str\", \"value\": \"Clayton Kershaw\", \"validators\": { \"choice\": { \"choices\": [\"Clayton Kershaw\", \"Jacob deGrom\", \"Justin Verlander\"] } } } } COMP builds the model parameter GUI directly from this data:","title":"Inputs"},{"location":"publish/inputs/#inputs","text":"COMP uses the ParamTools inputs format for building its GUI. ParamTools also offers functionality for updating parameter values and validating the new values. Check out the ParamTools documentation for more information on how to create your configuration files. COMP requires two typs of inputs: meta parameters and model parameters. First, what are meta parameters ? Meta parameters control the default parameters. If the value of a parameter depends on the current year, then the user will need to set the current year via a meta parameter before they can view the parameter's default value and update it.","title":"Inputs"},{"location":"publish/inputs/#meta-parameters","text":"For example, the meta parameters for PSLmodels/Tax-Brain are defined like this: { \"schema\": { \"labels\": {}, \"additional_members\": {} }, \"start_year\": { \"title\": \"Start Year\", \"description\": \"Year for parameters.\", \"type\": \"int\", \"value\": 2019, \"validators\": {\"range\": {\"min\": 2019, \"max\": 2027}} }, \"data_source\": { \"title\": \"Data Source\", \"description\": \"Data source can be PUF or CPS\", \"type\": \"str\", \"value\": \"PUF\", \"validators\": {\"choice\": {\"choices\": [\"PUF\", \"CPS\"]}} }, \"use_full_sample\": { \"title\": \"Use Full Sample\", \"description\": \"Use entire data set or a 2% sample.\", \"type\": \"str\", \"value\": true, \"validators\": {} } } COMP uses this information to build a set of controls that dictate which values of the default model parameters are shown:","title":"Meta Parameters"},{"location":"publish/inputs/#default-parameters","text":"The GUI is built directly from the default parameters. Here's an example using a subset of the inputs from the hdoupe/Matchups app: { \"schema\": { \"labels\": { \"use_full_data\": {\"type\": \"bool\", \"validators\": {}} }, \"additional_parameters\": { \"section_1\": {\"type\": \"str\", \"number_dims\": 0}, \"section_2\": {\"type\": \"str\", \"number_dims\": 0} } }, \"start_date\": { \"title\": \"Start Date\", \"description\": \"Date to start pulling statcast information\", \"section_1\": \"Date\", \"section_2\": \"\", \"notes\": \"If using the 2018 dataset, only use dates in 2018.\", \"type\": \"date\", \"value\": [ {\"use_full_data\": true, \"value\": \"2008-01-01\"}, {\"use_full_data\": false, \"value\": \"2018-01-01\"} ], \"validators\": {\"date_range\": {\"min\": \"2008-01-01\", \"max\": \"end_date\"}} }, \"pitcher\": { \"title\": \"Pitcher Name\", \"description\": \"Name of pitcher to pull data on\", \"section_1\": \"Parameters\", \"section_2\": \"Pitcher\", \"type\": \"str\", \"value\": \"Clayton Kershaw\", \"validators\": { \"choice\": { \"choices\": [\"Clayton Kershaw\", \"Jacob deGrom\", \"Justin Verlander\"] } } } } COMP builds the model parameter GUI directly from this data:","title":"Default Parameters"},{"location":"publish/outputs/","text":"Outputs Projects should return outputs that are in the following format: { \"renderable\": [ { \"media_type\": \"PNG\", \"title\": \"My PNG\", \"data\": \"picture bytes here...\" } ], \"downloadable\": [ { \"media_type\": \"CSV\", \"title\": \"My CSV\", \"data\": \"comma,sep,values\\n\" } ] } There are two categories of outputs: \"renderable\" and \"downloadable.\" Renderable outputs will be displayed on the outputs page while downloadable outputs are saved by the user as a zipfile. These categories are represented as the two top-level members in the JSON structure above. They point to a List of Output Objects . Each Output Object has three members: media_type , title , and data . Supported media types are: bokeh table CSV PNG JPEG MP3 MP4 Here's an example for how to create a full result in Python: def append_output(df, title, renderable, downloadable): js, div = make_my_plot(df, title) renderable.append( { \"media_type\": \"bokeh\", \"title\": title, \"data\": { \"javascript\": js, \"html\": div } } ) downloadable.append( { \"media_type\": \"CSV\", \"title\": title, \"data\": df.to_csv() } ) downloadable = [] renderable = [] append_output(my_df, \"My results\", renderable, downloadable) append_output(my_other_df, \"My other results\", renderable, downloadable) A full example can be found in the Matchups package . Examples bokeh JSON format: { \"media_type\": \"bokeh\", \"title\": \"My Bokeh Plot\", \"data\": { \"html\": \"<div>...</div>\", \"js\": \"<script>...</script>\" } } Python example: from bokeh.plotting import figure from bokeh.embed import components # see: https://bokeh.pydata.org/en/latest/docs/user_guide/quickstart.html#getting-started # prepare some data x = [1, 2, 3, 4, 5] y = [6, 7, 2, 4, 5] # create a new plot with a title and axis labels p = figure(title=\"simple line example\", x_axis_label='x', y_axis_label='y') # add a line renderer with legend and line thickness p.line(x, y, legend=\"Temp.\", line_width=2) # get the results js, div = components(p) output = { \"media_type\": \"bokeh\", \"title\": \"simple line example\", \"data\": { \"html\": div, \"js\": js } } table JSON format: { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": \"<table>...</table>\" } Python example: import pandas as pd df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]}) table = df.to_html() output = { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": table } CSV JSON format: { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": \"<table>...</table>\" } Python example: import pandas as pd df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]}) csv = df.to_csv() output = { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": csv }","title":"Ouptuts"},{"location":"publish/outputs/#outputs","text":"Projects should return outputs that are in the following format: { \"renderable\": [ { \"media_type\": \"PNG\", \"title\": \"My PNG\", \"data\": \"picture bytes here...\" } ], \"downloadable\": [ { \"media_type\": \"CSV\", \"title\": \"My CSV\", \"data\": \"comma,sep,values\\n\" } ] } There are two categories of outputs: \"renderable\" and \"downloadable.\" Renderable outputs will be displayed on the outputs page while downloadable outputs are saved by the user as a zipfile. These categories are represented as the two top-level members in the JSON structure above. They point to a List of Output Objects . Each Output Object has three members: media_type , title , and data . Supported media types are: bokeh table CSV PNG JPEG MP3 MP4 Here's an example for how to create a full result in Python: def append_output(df, title, renderable, downloadable): js, div = make_my_plot(df, title) renderable.append( { \"media_type\": \"bokeh\", \"title\": title, \"data\": { \"javascript\": js, \"html\": div } } ) downloadable.append( { \"media_type\": \"CSV\", \"title\": title, \"data\": df.to_csv() } ) downloadable = [] renderable = [] append_output(my_df, \"My results\", renderable, downloadable) append_output(my_other_df, \"My other results\", renderable, downloadable) A full example can be found in the Matchups package .","title":"Outputs"},{"location":"publish/outputs/#examples","text":"","title":"Examples"},{"location":"publish/outputs/#bokeh","text":"JSON format: { \"media_type\": \"bokeh\", \"title\": \"My Bokeh Plot\", \"data\": { \"html\": \"<div>...</div>\", \"js\": \"<script>...</script>\" } } Python example: from bokeh.plotting import figure from bokeh.embed import components # see: https://bokeh.pydata.org/en/latest/docs/user_guide/quickstart.html#getting-started # prepare some data x = [1, 2, 3, 4, 5] y = [6, 7, 2, 4, 5] # create a new plot with a title and axis labels p = figure(title=\"simple line example\", x_axis_label='x', y_axis_label='y') # add a line renderer with legend and line thickness p.line(x, y, legend=\"Temp.\", line_width=2) # get the results js, div = components(p) output = { \"media_type\": \"bokeh\", \"title\": \"simple line example\", \"data\": { \"html\": div, \"js\": js } }","title":"bokeh"},{"location":"publish/outputs/#table","text":"JSON format: { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": \"<table>...</table>\" } Python example: import pandas as pd df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]}) table = df.to_html() output = { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": table }","title":"table"},{"location":"publish/outputs/#csv","text":"JSON format: { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": \"<table>...</table>\" } Python example: import pandas as pd df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]}) csv = df.to_csv() output = { \"media_type\": \"table\", \"title\": \"My Table\", \"data\": csv }","title":"CSV"}]}